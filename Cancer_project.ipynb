{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdf6e11-54bf-4770-8d73-6958a1b5f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Cancer_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ecc3c0-6b3b-46d3-bd43-3bec47be4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 32', axis = 1, inplace = True)\n",
    "\n",
    "df.drop(columns = 'id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cfca3c-2dea-491a-a973-6faba46ffc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "L = LabelEncoder()\n",
    "\n",
    "df['diagnosis'] = L.fit_transform(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b374e81-f205-4ad5-a83c-e84f6778d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c595677e-1508-4283-aea8-8ed492d613dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis',axis=1)\n",
    "\n",
    "Y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab85507-fb69-4435-9f4e-bc339de10739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_s = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5b3c06-d368-4738-a320-c9575541212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5d12db-ee1c-45ca-8ace-bc668938ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d79b4e-f935-4d6d-bb0d-50e4a7d2e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9b3a44-1a44-49a4-8f8d-e5e599596b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d037a52-02b9-4c02-b94f-c29e180974a5",
   "metadata": {},
   "source": [
    "Логистическая регрессия предсказывает вероятность принадлежности объекта классу. Сигмоида позволяет превратить любой диапазон в значения от 0 до 1, она используется как логистическая функция. (1/(1+е^(-х)). Можно использовать линейную модель и затем полученные значения обрабатывать с помощью сигмоиды и получать необходимые вероятности, а из них метки класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb59fb9-11b8-4fc9-92d0-6fec7b2c9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ae46b-330c-4a38-aec0-d9a03ce50114",
   "metadata": {},
   "source": [
    "Алгоритм k ближайших соседей обучается на основе рассмотра новых данных на следующем шаге. Пусть некоторое число объектов имеют метку. Вносим новый объект, считаем расстояния до всех других объектов. Выбираем k ближайших соседей объекта и ставим объекту метку, которая наиболее часто встречается среди них. Сначала k произвольное/рандомное, затем подбирается на основе точности аппроксимаций меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f6bb46-fd9f-449c-a531-3db708f064c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac148d-47e0-4c88-87be-17cae6d02a1a",
   "metadata": {},
   "source": [
    "Байессовские классификаторы - достаточно широкий класс алгоритмов, основанных на апостериорных вероятностях. Они считают плотности распределения уже известными, однако в реальности их можно только оценить по обучающей выборке, в связи с чем количество объектов в ней должно быть достаточно большим, чтобы избежать переобучения.\n",
    "\n",
    "Гауссовский nb классификатор считает распределения нормальными.\n",
    "\n",
    "Признаки считаются независимыми и имеющими одинаковый вес, поэтому рассматриваются вероятность принадлежности классу по всем признакам отдельно, затем из этого получается общая вероятность принадлежности к классу, а из этого получается метка класса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7fa996-bce0-4ce9-93d7-2f9d5600e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25cb1b52-882c-4721-89bb-7758b89f8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "358b24ac-a377-44ea-ad07-195c70a8a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), KNeighborsClassifier(), GaussianNB(),\n",
    "         DecisionTreeClassifier(), MLPClassifier(solver='lbfgs', activation = 'relu', alpha = 1e-5, hidden_layer_sizes = (150, ), random_state = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "906d0ea9-8bbe-4207-9a23-fe12f9935a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c0b74a4-22c2-4c70-8f2e-9755d91e0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(X_s, Y, test_size = 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d2778a9-dc41-4508-a326-276f0e049b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "Average time: 0.003247027397155762\n",
      "Max time: 0.00943899154663086\n",
      "Min time: 0.002454996109008789\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average time: 0.006153378486633301\n",
      "Max time: 0.007302284240722656\n",
      "Min time: 0.005691051483154297\n",
      "\n",
      "GaussianNB()\n",
      "Average time: 0.00047936916351318357\n",
      "Max time: 0.001567840576171875\n",
      "Min time: 0.000431060791015625\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average time: 0.002784566879272461\n",
      "Max time: 0.0031881332397460938\n",
      "Min time: 0.002534151077270508\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average time: 0.030308961868286133\n",
      "Max time: 0.07454895973205566\n",
      "Min time: 0.020652055740356445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    \n",
    "    times = []\n",
    "        \n",
    "    for __ in range(50):\n",
    "        \n",
    "        tstart = time.time()\n",
    "    \n",
    "        model.fit(xtr , ytr)\n",
    "    \n",
    "        ypre = model.predict(xte)\n",
    "        \n",
    "        tend = time.time()\n",
    "        \n",
    "        t = tend - tstart\n",
    "        \n",
    "        times.append(t)\n",
    "        \n",
    "    print(model)\n",
    "    \n",
    "    print( f\"Average time: {np.mean(np.array(times))}\" )\n",
    "        \n",
    "    print( f\"Max time: {np.max(np.array(times))}\" )\n",
    "        \n",
    "    print( f\"Min time: {np.min(np.array(times))}\" )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d205b7-37d4-4e8c-9b93-298b9d9dd8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 1\n",
      "LogisticRegression()\n",
      "Average accuracy on tetsting set: 0.9555035128805619\n",
      "Max accuracy on tetsting set: 0.955503512880562\n",
      "Min accuracy on tetsting set: 0.955503512880562\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on tetsting set: 0.9508196721311476\n",
      "Max accuracy on tetsting set: 0.9508196721311475\n",
      "Min accuracy on tetsting set: 0.9508196721311475\n",
      "\n",
      "GaussianNB()\n",
      "Average accuracy on tetsting set: 0.9250585480093678\n",
      "Max accuracy on tetsting set: 0.9250585480093677\n",
      "Min accuracy on tetsting set: 0.9250585480093677\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average accuracy on tetsting set: 0.9126463700234192\n",
      "Max accuracy on tetsting set: 0.9320843091334895\n",
      "Min accuracy on tetsting set: 0.8782201405152225\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average accuracy on tetsting set: 0.9391100702576113\n",
      "Max accuracy on tetsting set: 0.9391100702576113\n",
      "Min accuracy on tetsting set: 0.9391100702576113\n",
      "\n",
      "Sample number: 2\n",
      "LogisticRegression()\n",
      "Average accuracy on tetsting set: 0.9765807962529273\n",
      "Max accuracy on tetsting set: 0.9765807962529274\n",
      "Min accuracy on tetsting set: 0.9765807962529274\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on tetsting set: 0.9437939110070259\n",
      "Max accuracy on tetsting set: 0.9437939110070258\n",
      "Min accuracy on tetsting set: 0.9437939110070258\n",
      "\n",
      "GaussianNB()\n",
      "Average accuracy on tetsting set: 0.9414519906323185\n",
      "Max accuracy on tetsting set: 0.9414519906323185\n",
      "Min accuracy on tetsting set: 0.9414519906323185\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average accuracy on tetsting set: 0.923185011709602\n",
      "Max accuracy on tetsting set: 0.9297423887587822\n",
      "Min accuracy on tetsting set: 0.9156908665105387\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average accuracy on tetsting set: 0.9601873536299765\n",
      "Max accuracy on tetsting set: 0.9601873536299765\n",
      "Min accuracy on tetsting set: 0.9601873536299765\n",
      "\n",
      "Sample number: 3\n",
      "LogisticRegression()\n",
      "Average accuracy on tetsting set: 0.9718969555035131\n",
      "Max accuracy on tetsting set: 0.9718969555035128\n",
      "Min accuracy on tetsting set: 0.9718969555035128\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on tetsting set: 0.9531615925058545\n",
      "Max accuracy on tetsting set: 0.9531615925058547\n",
      "Min accuracy on tetsting set: 0.9531615925058547\n",
      "\n",
      "GaussianNB()\n",
      "Average accuracy on tetsting set: 0.9344262295081969\n",
      "Max accuracy on tetsting set: 0.9344262295081968\n",
      "Min accuracy on tetsting set: 0.9344262295081968\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average accuracy on tetsting set: 0.905152224824356\n",
      "Max accuracy on tetsting set: 0.9250585480093677\n",
      "Min accuracy on tetsting set: 0.8875878220140515\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average accuracy on tetsting set: 0.9578454332552692\n",
      "Max accuracy on tetsting set: 0.9578454332552693\n",
      "Min accuracy on tetsting set: 0.9578454332552693\n",
      "\n",
      "Sample number: 4\n",
      "LogisticRegression()\n",
      "Average accuracy on tetsting set: 0.9718969555035131\n",
      "Max accuracy on tetsting set: 0.9718969555035128\n",
      "Min accuracy on tetsting set: 0.9718969555035128\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on tetsting set: 0.946135831381733\n",
      "Max accuracy on tetsting set: 0.9461358313817331\n",
      "Min accuracy on tetsting set: 0.9461358313817331\n",
      "\n",
      "GaussianNB()\n",
      "Average accuracy on tetsting set: 0.9391100702576113\n",
      "Max accuracy on tetsting set: 0.9391100702576113\n",
      "Min accuracy on tetsting set: 0.9391100702576113\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average accuracy on tetsting set: 0.9107728337236534\n",
      "Max accuracy on tetsting set: 0.9297423887587822\n",
      "Min accuracy on tetsting set: 0.8946135831381733\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average accuracy on tetsting set: 0.9601873536299765\n",
      "Max accuracy on tetsting set: 0.9601873536299765\n",
      "Min accuracy on tetsting set: 0.9601873536299765\n",
      "\n",
      "Sample number: 5\n",
      "LogisticRegression()\n",
      "Average accuracy on tetsting set: 0.9812646370023419\n",
      "Max accuracy on tetsting set: 0.9812646370023419\n",
      "Min accuracy on tetsting set: 0.9812646370023419\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on tetsting set: 0.9718969555035131\n",
      "Max accuracy on tetsting set: 0.9718969555035128\n",
      "Min accuracy on tetsting set: 0.9718969555035128\n",
      "\n",
      "GaussianNB()\n",
      "Average accuracy on tetsting set: 0.9484777517564403\n",
      "Max accuracy on tetsting set: 0.9484777517564403\n",
      "Min accuracy on tetsting set: 0.9484777517564403\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Average accuracy on tetsting set: 0.9257611241217798\n",
      "Max accuracy on tetsting set: 0.9437939110070258\n",
      "Min accuracy on tetsting set: 0.9063231850117096\n",
      "\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(150,), random_state=1,\n",
      "              solver='lbfgs')\n",
      "Average accuracy on tetsting set: 0.9695550351288057\n",
      "Max accuracy on tetsting set: 0.9695550351288056\n",
      "Min accuracy on tetsting set: 0.9695550351288056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    \n",
    "    xtr, xte, ytr, yte = train_test_split(X_s, Y, test_size = 0.75)\n",
    "    \n",
    "    print(f\"Sample number: {_+1}\")\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        accs = []\n",
    "        \n",
    "        for __ in range(10):\n",
    "    \n",
    "            model.fit(xtr , ytr)\n",
    "    \n",
    "            ypre = model.predict(xte)\n",
    "        \n",
    "            accs.append(accuracy_score(ypre, yte))\n",
    "        \n",
    "        print(model)\n",
    "    \n",
    "        print( f\"Average accuracy on tetsting set: {np.mean(np.array(accs))}\" )\n",
    "        \n",
    "        print( f\"Max accuracy on tetsting set: {np.max(np.array(accs))}\" )\n",
    "        \n",
    "        print( f\"Min accuracy on tetsting set: {np.min(np.array(accs))}\" )\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4accfb4-a663-4780-9998-f39cbbfb49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), GaussianNB(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b58668e-21e7-4a7c-ae76-b2727cd2fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch of 50 samples number: 1\n",
      "LogisticRegression()\n",
      "Average accuracy on testing set: 0.9824561403508769\n",
      "Max accuracy on testing set: 0.9824561403508771\n",
      "Min accuracy on testing set: 0.9824561403508771\n",
      "\n",
      "Sample batch of 50 samples number: 1\n",
      "GaussianNB()\n",
      "Average accuracy on testing set: 0.9166666666666664\n",
      "Max accuracy on testing set: 0.9166666666666666\n",
      "Min accuracy on testing set: 0.9166666666666666\n",
      "\n",
      "Sample batch of 50 samples number: 1\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on testing set: 0.960526315789474\n",
      "Max accuracy on testing set: 0.9605263157894737\n",
      "Min accuracy on testing set: 0.9605263157894737\n",
      "\n",
      "Sample batch of 50 samples number: 2\n",
      "LogisticRegression()\n",
      "Average accuracy on testing set: 0.9736842105263155\n",
      "Max accuracy on testing set: 0.9736842105263158\n",
      "Min accuracy on testing set: 0.9736842105263158\n",
      "\n",
      "Sample batch of 50 samples number: 2\n",
      "GaussianNB()\n",
      "Average accuracy on testing set: 0.960526315789474\n",
      "Max accuracy on testing set: 0.9605263157894737\n",
      "Min accuracy on testing set: 0.9605263157894737\n",
      "\n",
      "Sample batch of 50 samples number: 2\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on testing set: 0.9780701754385962\n",
      "Max accuracy on testing set: 0.9780701754385965\n",
      "Min accuracy on testing set: 0.9780701754385965\n",
      "\n",
      "Sample batch of 50 samples number: 3\n",
      "LogisticRegression()\n",
      "Average accuracy on testing set: 0.9868421052631577\n",
      "Max accuracy on testing set: 0.9868421052631579\n",
      "Min accuracy on testing set: 0.9868421052631579\n",
      "\n",
      "Sample batch of 50 samples number: 3\n",
      "GaussianNB()\n",
      "Average accuracy on testing set: 0.960526315789474\n",
      "Max accuracy on testing set: 0.9605263157894737\n",
      "Min accuracy on testing set: 0.9605263157894737\n",
      "\n",
      "Sample batch of 50 samples number: 3\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on testing set: 0.9780701754385962\n",
      "Max accuracy on testing set: 0.9780701754385965\n",
      "Min accuracy on testing set: 0.9780701754385965\n",
      "\n",
      "Sample batch of 50 samples number: 4\n",
      "LogisticRegression()\n",
      "Average accuracy on testing set: 0.9649122807017547\n",
      "Max accuracy on testing set: 0.9649122807017544\n",
      "Min accuracy on testing set: 0.9649122807017544\n",
      "\n",
      "Sample batch of 50 samples number: 4\n",
      "GaussianNB()\n",
      "Average accuracy on testing set: 0.9166666666666664\n",
      "Max accuracy on testing set: 0.9166666666666666\n",
      "Min accuracy on testing set: 0.9166666666666666\n",
      "\n",
      "Sample batch of 50 samples number: 4\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on testing set: 0.9517543859649125\n",
      "Max accuracy on testing set: 0.9517543859649122\n",
      "Min accuracy on testing set: 0.9517543859649122\n",
      "\n",
      "Sample batch of 50 samples number: 5\n",
      "LogisticRegression()\n",
      "Average accuracy on testing set: 0.9868421052631577\n",
      "Max accuracy on testing set: 0.9868421052631579\n",
      "Min accuracy on testing set: 0.9868421052631579\n",
      "\n",
      "Sample batch of 50 samples number: 5\n",
      "GaussianNB()\n",
      "Average accuracy on testing set: 0.9517543859649125\n",
      "Max accuracy on testing set: 0.9517543859649122\n",
      "Min accuracy on testing set: 0.9517543859649122\n",
      "\n",
      "Sample batch of 50 samples number: 5\n",
      "KNeighborsClassifier()\n",
      "Average accuracy on testing set: 0.9736842105263155\n",
      "Max accuracy on testing set: 0.9736842105263158\n",
      "Min accuracy on testing set: 0.9736842105263158\n",
      "\n",
      "LogisticRegression()\n",
      "Overall average accuracy: 0.9755964912280699\n",
      "Overall max accuracy: 1.0\n",
      "Overall min accuracy: 0.9473684210526315\n",
      "\n",
      "GaussianNB()\n",
      "Overall average accuracy: 0.9328421052631579\n",
      "Overall max accuracy: 0.9780701754385965\n",
      "Overall min accuracy: 0.8903508771929824\n",
      "\n",
      "KNeighborsClassifier()\n",
      "Overall average accuracy: 0.9626140350877194\n",
      "Overall max accuracy: 0.9912280701754386\n",
      "Overall min accuracy: 0.9298245614035088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_max = {str(model): [] for model in models}\n",
    "\n",
    "d_min = {str(model): [] for model in models}\n",
    "\n",
    "d_mean = {str(model): [] for model in models}\n",
    "\n",
    "for _ in range(250):\n",
    "    \n",
    "    xtr, xte, ytr, yte = train_test_split(X_s, Y, test_size = 0.40)\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        accs = []\n",
    "        \n",
    "        for __ in range(15):\n",
    "    \n",
    "            model.fit(xtr , ytr)\n",
    "    \n",
    "            ypre = model.predict(xte)\n",
    "        \n",
    "            accs.append(accuracy_score(ypre, yte))\n",
    "            \n",
    "        d_max[ str(model) ].append(np.max(np.array(accs)))\n",
    "        \n",
    "        d_min[ str(model) ].append(np.min(np.array(accs)))\n",
    "        \n",
    "        d_mean[ str(model) ].append(np.mean(np.array(accs)))\n",
    "        \n",
    "        if (int(_+1) % 50 == 0):\n",
    "            \n",
    "            print(f\"Sample batch of 50 samples number: {( (_+1) // 50 )}\")\n",
    "        \n",
    "            print(model)\n",
    "    \n",
    "            print( f\"Average accuracy on testing set: {np.mean(np.array( d_mean[str(model)][_ : _+50] ))}\" )\n",
    "        \n",
    "            print( f\"Max accuracy on testing set: {np.max(np.array( d_max[str(model)][_ : _+50] ))}\" )\n",
    "        \n",
    "            print( f\"Min accuracy on testing set: {np.min(np.array( d_min[str(model)][_ : _+50] ))}\" )\n",
    "\n",
    "            print()\n",
    "            \n",
    "for model in models:\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    print( f\"Overall average accuracy: {np.mean(np.array( d_mean[str(model)] ))}\" )\n",
    "        \n",
    "    print( f\"Overall max accuracy: {np.max(np.array( d_max[str(model)] ))}\" )\n",
    "        \n",
    "    print( f\"Overall min accuracy: {np.min(np.array( d_min[str(model)] ))}\" )\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89c828-878c-43cd-ad46-380f95f23deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
